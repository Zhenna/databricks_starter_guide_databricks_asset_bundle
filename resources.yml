resources:
  jobs:
    etl_pipeline:
      name: nightly-etl-job
      tasks:
        - task_key: run_etl
          description: Run ETL logic
          python_wheel_task:
            entry_point: main
          job_cluster_key: shared_cluster
      job_clusters:
        - job_cluster_key: shared_cluster
          new_cluster:
            spark_version: 13.3.x-scala2.12
            node_type_id: Standard_DS3_v2
            num_workers: 2
